{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmenter:\n",
    "    def __init__(self, transforms, num_aug):\n",
    "        self.num_aug = num_aug\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        assert num_aug > 0, \"number of augmentations should be at least 1.\"\n",
    "        \n",
    "    def apply_augments(self, img):\n",
    "        augmented = []\n",
    "        for i in range(self.num_aug):\n",
    "            if i == 0:\n",
    "                augmented += [transforms.ToTensor()(img)]\n",
    "            else:\n",
    "                augmented += [self.transforms(img)]\n",
    "        return augmented\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "                transforms.RandomChoice([\n",
    "                    transforms.RandomAffine((-90, 90)),\n",
    "                    transforms.RandomAffine(0, translate=(0.2, 0.4)),\n",
    "                    transforms.RandomAffine(0, scale=(0.8, 1.1)),\n",
    "                    transforms.RandomAffine(0, shear=(-20, 20))]), \n",
    "                transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(augmenter):\n",
    "    def form_batch(batch):\n",
    "        batch_img = []\n",
    "        batch_lbl = []\n",
    "        batch_idx = []\n",
    "\n",
    "        for idx, (img, lbl) in enumerate(batch):\n",
    "            aug_img = augmenter.apply_augments(img)\n",
    "            aug_lbl = np.repeat(lbl, augmenter.num_aug).tolist()\n",
    "            aug_idx = np.repeat(idx, augmenter.num_aug).tolist()\n",
    "            \n",
    "            batch_img += aug_img\n",
    "            batch_lbl += aug_lbl\n",
    "            batch_idx += aug_idx\n",
    "        \n",
    "        return (torch.stack(batch_img).float(),\n",
    "                torch.tensor(batch_lbl, dtype=torch.int),\n",
    "                torch.tensor(batch_idx, dtype=torch.int))\n",
    "    return form_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(\"~/Datasets/mnist/\")\n",
    "trainset.num_classes = 10\n",
    "augmenter = DataAugmenter(transform, 10)\n",
    "trainloader = DataLoader(trainset, batch_size=100 // 10, collate_fn=collate_fn(augmenter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_noise(trainset, ratio, seed):\n",
    "    assert 0 <= ratio <= 1., 'ratio is bounded between 0 and 1' \n",
    "    np.random.seed(seed)\n",
    "    train_labels = trainset.targets.numpy()\n",
    "    train_labels_gt = train_labels.copy()\n",
    "    for i in range(trainset.num_classes):\n",
    "        indices = np.where(train_labels == i)[0]\n",
    "        np.random.shuffle(indices)\n",
    "        for j, idx in enumerate(indices):\n",
    "            if j < ratio * len(indices):\n",
    "#                 self.noise_indx.append(idx)\n",
    "                # truck -> automobile\n",
    "                if i == 9:\n",
    "                    train_labels[idx] = 1\n",
    "                # bird -> airplane\n",
    "                elif i == 2:\n",
    "                    train_labels[idx] = 0\n",
    "                # cat -> dog\n",
    "                elif i == 3:\n",
    "                    train_labels[idx] = 5\n",
    "                # dog -> cat\n",
    "                elif i == 5:\n",
    "                    train_labels[idx] = 3\n",
    "                # deer -> horse\n",
    "                elif i == 4:\n",
    "                    train_labels[idx] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
      "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0])\n",
      "tensor([5, 0, 7, 1, 9, 2, 1, 5, 1, 7, 3, 5, 3, 6, 1, 7, 2, 8, 6, 1, 4, 0, 9, 1,\n",
      "        1, 2, 7, 5, 2, 7, 5, 8, 6, 9, 0, 3, 6, 0, 7, 6, 1, 8, 7, 1, 3, 1, 8, 5,\n",
      "        9, 3, 5, 0, 7, 4, 1, 8, 0, 1, 4, 1, 7, 4, 6, 0, 7, 5, 6, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(trainset.targets[:70])\n",
    "asymmetric_noise(trainset, 0.5, 10)\n",
    "print(trainset.targets[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_noisify(y, P, random_state):\n",
    "    \"\"\" Flip classes according to transition probability matrix T.\n",
    "    It expects a number between 0 and the number of classes - 1.\n",
    "    \"\"\"\n",
    "#     print (np.max(y), P.shape[0])\n",
    "    assert P.shape[0] == P.shape[1]\n",
    "    assert np.max(y) < P.shape[0]\n",
    "\n",
    "    # row stochastic matrix\n",
    "    assert np.allclose(P.sum(axis=1), np.ones(P.shape[1]))\n",
    "    assert (P >= 0.0).all()\n",
    "\n",
    "    m = y.shape[0]\n",
    "#     print(m)\n",
    "    new_y = y.copy()\n",
    "    flipper = np.random.RandomState(random_state)\n",
    "\n",
    "    for idx in np.arange(m):\n",
    "        i = y[idx]\n",
    "        # draw a vector with only an 1\n",
    "        flipped = flipper.multinomial(1, P[i, :], 1)[0]\n",
    "        new_y[idx] = np.where(flipped == 1)[0]\n",
    "\n",
    "    return new_y\n",
    "\n",
    "\n",
    "# noisify_pairflip call the function \"multiclass_noisify\"\n",
    "def noisify_pairflip(y_train, noise, seed=None):\n",
    "    \"\"\"mistakes:\n",
    "        flip in the pair\n",
    "    \"\"\"\n",
    "    y_train = trainset.targets.numpy()\n",
    "    nb_classes = np.unique(trainset.targets).size\n",
    "    P = np.eye(nb_classes)\n",
    "    n = noise\n",
    "\n",
    "    if n > 0.0:\n",
    "        # 0 -> 1\n",
    "        P[0, 0], P[0, 1] = 1. - n, n\n",
    "        for i in range(1, nb_classes-1):\n",
    "            P[i, i], P[i, i + 1] = 1. - n, n\n",
    "        P[nb_classes-1, nb_classes-1], P[nb_classes-1, 0] = 1. - n, n\n",
    "\n",
    "        y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "                                           random_state=seed)\n",
    "        actual_noise = (y_train_noisy != y_train).mean()\n",
    "        assert actual_noise > 0.0\n",
    "#         print('Actual noise %.2f' % actual_noise)\n",
    "        y_train = y_train_noisy\n",
    "\n",
    "    return y_train, actual_noise,P\n",
    "\n",
    "def noisify_multiclass_symmetric(trainset, noise, seed=10):\n",
    "    \"\"\"mistakes:\n",
    "        flip in the symmetric way\n",
    "    \"\"\"\n",
    "    y_train = trainset.targets.numpy()\n",
    "    nb_classes = np.unique(y_train).size\n",
    "    P = np.ones((nb_classes, nb_classes))\n",
    "    n = noise\n",
    "    P = (n / (nb_classes - 1)) * P\n",
    "\n",
    "    if n > 0.0:\n",
    "        # 0 -> 1\n",
    "        P[0, 0] = 1. - n\n",
    "        for i in range(1, nb_classes-1):\n",
    "            P[i, i] = 1. - n\n",
    "        P[nb_classes-1, nb_classes-1] = 1. - n\n",
    "\n",
    "        y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "                                           random_state=seed)\n",
    "        actual_noise = (y_train_noisy != y_train).mean()\n",
    "        assert actual_noise > 0.0\n",
    "#         print('Actual noise %.2f' % actual_noise)\n",
    "        y_train = y_train_noisy\n",
    "    \n",
    "    return y_train, actual_noise, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "before = trainset.targets \n",
    "noisify_pairflip(trainset, 0.5, 10)[0][:60]\n",
    "after = trainset.targets\n",
    "print(before.eq(after).sum().item())\n",
    "# noisify_multiclass_symmetric(trainset, 0.5, 10)[0][:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([False, True]).eq(torch.tensor([True, False])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
