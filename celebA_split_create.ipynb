{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import csv\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from torchvision.datasets.utils import check_integrity, download_and_extract_archive, download_url, verify_str_arg, download_file_from_google_drive, extract_archive\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "CSV = namedtuple(\"CSV\", [\"header\", \"index\", \"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataroot = '/home/fusang/Desktop/mcr2/data/celebA/celeba'\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _load_csv(\n",
    "    filename: str,\n",
    "    header = None,\n",
    "):\n",
    "    with open(os.path.join(dataroot, filename)) as csv_file:\n",
    "        data = list(csv.reader(csv_file, delimiter=\" \", skipinitialspace=True))\n",
    "\n",
    "    if header is not None:\n",
    "        headers = data[header]\n",
    "        data = data[header + 1 :]\n",
    "    else:\n",
    "        headers = []\n",
    "\n",
    "    indices = [row[0] for row in data]\n",
    "    data = [row[1:] for row in data]\n",
    "    data_int = [list(map(int, i)) for i in data]\n",
    "\n",
    "    return CSV(headers, indices, torch.tensor(data_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_map = {\n",
    "    \"train\": 0,\n",
    "    \"valid\": 1,\n",
    "    \"test\": 2,\n",
    "    \"all\": None,\n",
    "}\n",
    "split = 'train'\n",
    "split_ = split_map[verify_str_arg(split.lower(), \"   \", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "# print(\"using data split:\",split_)\n",
    "splits = _load_csv(\"list_eval_partition.txt\")\n",
    "# print(splits.data.shape)\n",
    "identity = _load_csv(\"identity_CelebA.txt\")\n",
    "# bbox = _load_csv(\"list_bbox_celeba.txt\", header=1)\n",
    "# landmarks_align = _load_csv(\"list_landmarks_align_celeba.txt\", header=1)\n",
    "attr = _load_csv(\"list_attr_celeba.txt\", header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask1 = slice(None) if split_ is None else (splits.data == split_).squeeze() # mask for train valid and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "identity = identity.data[:]\n",
    "# bbox = bbox.data[:]\n",
    "# andmarks_align = landmarks_align.data[:]\n",
    "attr_names = attr.header\n",
    "attr = attr.data[:]\n",
    "attr = torch.div(attr + 1, 2, rounding_mode=\"floor\") # map from {-1, 1} to {0, 1}\n",
    "\n",
    "classes = np.array([19, 31, 34])\n",
    "attr = attr.cpu().detach().numpy()\n",
    "attr = attr[:, classes]\n",
    "num_attrs = int(len(classes))\n",
    "C = np.array([2 ** x for x in range(num_attrs)]).reshape(num_attrs,1)\n",
    "class_list = np.dot(attr, C)\n",
    "# print(\"class_list\", class_list.shape)\n",
    "targets_ = np.squeeze(class_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing class information\n",
      "['High_Cheekbones' 'Smiling' 'Wearing_Earrings']\n",
      "selected label:[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "maxnumber of imgs per class:100000\n",
      "##################################################\n",
      "statistic information for the whole celebA dataset\n",
      "class 0: number [81666] before masking\n",
      "class 1: number [10187] before masking\n",
      "class 2: number [17141] before masking\n",
      "class 3: number [55329] before masking\n",
      "class 4: number [9974] before masking\n",
      "class 5: number [3103] before masking\n",
      "class 6: number [1629] before masking\n",
      "class 7: number [23570] before masking\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"showing class information\")\n",
    "attr_names = np.array(attr_names)[classes]\n",
    "print(attr_names)\n",
    "selected_labels = [0,1,2,3,4,5,6,7]\n",
    "num_imgs_per_class = 100000\n",
    "selected_pos = np.array([])\n",
    "mask2 = np.zeros(splits.data.shape[0],dtype=bool) # mask of label classes\n",
    "print(f'selected label:{selected_labels}')\n",
    "print(f'maxnumber of imgs per class:{num_imgs_per_class}')\n",
    "\n",
    "print(\"##################################################\")\n",
    "print(\"statistic information for the whole celebA dataset\")\n",
    "for i in selected_labels:\n",
    "    temp = class_list == i\n",
    "    print(f\"class {i}: number {sum(temp)} before masking\")\n",
    "    pos_temp,_ = np.where(class_list == i)\n",
    "    pos_temp = np.array(pos_temp)\n",
    "    np.random.shuffle(pos_temp)\n",
    "    selected_pos = np.concatenate((selected_pos, pos_temp[:num_imgs_per_class]))\n",
    "print(\"##################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_subset_mask(remove_label, class_list, attr_names, split):\n",
    "    split_map = {\n",
    "    \"train\": 0,\n",
    "    \"valid\": 1,\n",
    "    \"test\": 2,\n",
    "    \"all\": None,\n",
    "    }\n",
    "    split = split\n",
    "    split_ = split_map[verify_str_arg(split.lower(), \"   \", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "    splits = _load_csv(\"list_eval_partition.txt\")\n",
    "\n",
    "    mask1 = slice(None) if split_ is None else (splits.data == split_).squeeze() # mask for train valid and test data\n",
    "    \n",
    "    selected_labels = [0,1,2,3,4,5,6,7]\n",
    "    selected_labels.remove(remove_label)\n",
    "    num_imgs_per_class = 2000\n",
    "    selected_pos = np.array([])\n",
    "    mask2 = np.zeros(splits.data.shape[0],dtype=bool) # mask of label classes\n",
    "    print(f'selected label:{selected_labels}')\n",
    "    print(f'maxnumber of imgs per class:{num_imgs_per_class}')\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    print(\"statistic information for the whole celebA dataset\")\n",
    "    for i in selected_labels:\n",
    "        temp = class_list == i\n",
    "        print(f\"class {i}: number {sum(temp)} before masking\")\n",
    "        pos_temp,_ = np.where(class_list == i)\n",
    "        pos_temp = np.array(pos_temp)\n",
    "        np.random.shuffle(pos_temp)\n",
    "        selected_pos = np.concatenate((selected_pos, pos_temp[:num_imgs_per_class]))\n",
    "    print(\"##################################################\")\n",
    "\n",
    "    selected_pos = np.array(selected_pos,dtype=int)\n",
    "    mask2[selected_pos] = True\n",
    "    # mask2 = torch.from_numpy(mask2)\n",
    "\n",
    "    mask = mask1 * mask2\n",
    "    filename = [splits.index[i] for i in torch.squeeze(torch.nonzero(mask))]\n",
    "    targets = [targets_[i] for i in torch.squeeze(torch.nonzero(mask))]\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    print(\"statistic information for the CUNSTOM dataset\")\n",
    "    # show class information\n",
    "    print(\"showing class information\")\n",
    "    attr_names = np.array(attr_names)[classes]\n",
    "    print(attr_names)\n",
    "\n",
    "    class_list = np.array(targets, dtype=int)\n",
    "    for i in range(2**(len(classes))):\n",
    "        temp = class_list == i\n",
    "        # pos_temp,_ = np.where(class_list == i)\n",
    "        # pos_temp = np.array(pos_temp)\n",
    "        print(f\"class {i}: number {sum(temp)}\")\n",
    "    print(\"##################################################\")\n",
    "    np.save(f'celeba_no{remove_label}_cls_{split}.npy',mask)\n",
    "    print(f'mask saving to celeba_no{remove_label}_cls_{split_}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected label:[1, 2, 3, 4, 5, 6, 7]\n",
      "maxnumber of imgs per class:2000\n",
      "##################################################\n",
      "statistic information for the whole celebA dataset\n",
      "class 1: number [10187] before masking\n",
      "class 2: number [17141] before masking\n",
      "class 3: number [55329] before masking\n",
      "class 4: number [9974] before masking\n",
      "class 5: number [3103] before masking\n",
      "class 6: number [1629] before masking\n",
      "class 7: number [23570] before masking\n",
      "##################################################\n",
      "##################################################\n",
      "statistic information for the CUNSTOM dataset\n",
      "showing class information\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mfind_subset_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mfind_subset_mask\u001b[0;34m(remove_label, class_list, attr_names, split)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# show class information\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshowing class information\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m attr_names \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(attr_names)\n\u001b[1;32m     48\u001b[0m class_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(targets, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 19 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    for split in ['train','valid','test']:\n",
    "        find_subset_mask(i, class_list, attr_names, split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from utils.image_transform import NumpyResize, pil_loader\n",
    "\n",
    "def select_subset(mask_cls, inputPath, outputPath, maxNumber):\n",
    "    splits = _load_csv(\"/home/fusang/Desktop/pytorch_GAN_zoo/data/list_eval_partition.txt\")\n",
    "    # mask = np.load(mask_npy)\n",
    "    # mask = np.array(mask_cls, dtype=bool)\n",
    "    # mask = torch.from_numpy(mask)\n",
    "    imgList = [splits.index[i] for i in torch.squeeze(torch.nonzero(mask_cls))]\n",
    "    numImgs = len(imgList)\n",
    "    print('Number of Images:', numImgs)\n",
    "\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.mkdir(outputPath)\n",
    "\n",
    "    for index, item in enumerate(imgList[:maxNumber]):\n",
    "        path = os.path.join(inputPath, item)\n",
    "        img = np.array(pil_loader(path))\n",
    "        path = os.path.join(outputPath, item)\n",
    "        imageio.imwrite(path, img)\n",
    "    print(\"Finished saving subdataset to\", outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_cls_dataset(class_list, attr_names, split, inputPath, outputPath):\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.mkdir(outputPath)\n",
    "    if not os.path.isdir(os.path.join(outputPath,split)):\n",
    "        os.mkdir(os.path.join(outputPath,split))\n",
    "    split_map = {\n",
    "    \"train\": 0,\n",
    "    \"valid\": 1,\n",
    "    \"test\": 2,\n",
    "    \"all\": None,\n",
    "    }\n",
    "    split = split\n",
    "    split_ = split_map[verify_str_arg(split.lower(), \" \", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "    splits = _load_csv(\"list_eval_partition.txt\")\n",
    "\n",
    "    mask1 = slice(None) if split_ is None else (splits.data == split_).squeeze() # mask for train valid and test data\n",
    "    \n",
    "    selected_labels = [0,1,2,3,4,5,6,7]\n",
    "    num_imgs_per_class = 10000\n",
    "    selected_pos = np.array([])\n",
    "    # mask2 = np.zeros(splits.data.shape[0],dtype=bool) # mask of label classes\n",
    "    print(f'selected label:{selected_labels}')\n",
    "    print(f'maxnumber of imgs per class:{num_imgs_per_class}')\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    print(\"statistic information for the whole celebA dataset\")\n",
    "    for i in selected_labels:\n",
    "        temp = class_list == i\n",
    "        temp = torch.from_numpy(np.squeeze(temp))\n",
    "        # print(temp.shape)\n",
    "        # print(mask1.shape)\n",
    "        print(f\"class {i}: number {sum(temp)} before masking\")\n",
    "        mask = mask1*temp\n",
    "        print(mask.shape)\n",
    "        ouputPathTemp= os.path.join(outputPath, split, str(i))\n",
    "        print(outputPath)\n",
    "        select_subset(mask ,inputPath, ouputPathTemp, num_imgs_per_class)\n",
    "    print(\"##################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputPath = \"data/celebA/celeba/img_align_celeba\"\n",
    "outputPath = 'celebA_attrs1_cls'\n",
    "create_cls_dataset(class_list, attr_names, 'train', inputPath, outputPath)\n",
    "create_cls_dataset(class_list, attr_names, 'valid', inputPath, outputPath)\n",
    "create_cls_dataset(class_list, attr_names, 'test', inputPath, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "0: ['Black_Hair' 'Eyeglasses' 'Male'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ngp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f6d18b1a2acc1c39f3a18ab7d910eafd569dd9675b80fc75b05c8446de28cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
