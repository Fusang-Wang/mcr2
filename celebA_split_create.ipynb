{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import csv\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from torchvision.datasets.utils import check_integrity, download_and_extract_archive, download_url, verify_str_arg, download_file_from_google_drive, extract_archive\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "CSV = namedtuple(\"CSV\", [\"header\", \"index\", \"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataroot = '/data/fusang/fm/celeba_raw/Anno'\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _load_csv(\n",
    "    filename: str,\n",
    "    header = None,\n",
    "):\n",
    "    with open(os.path.join(dataroot, filename)) as csv_file:\n",
    "        data = list(csv.reader(csv_file, delimiter=\" \", skipinitialspace=True))\n",
    "\n",
    "    if header is not None:\n",
    "        headers = data[header]\n",
    "        data = data[header + 1 :]\n",
    "    else:\n",
    "        headers = []\n",
    "\n",
    "    indices = [row[0] for row in data]\n",
    "    data = [row[1:] for row in data]\n",
    "    data_int = [list(map(int, i)) for i in data]\n",
    "\n",
    "    return CSV(headers, indices, torch.tensor(data_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_map = {\n",
    "    \"train\": 0,\n",
    "    \"valid\": 1,\n",
    "    \"test\": 2,\n",
    "    \"all\": None,\n",
    "}\n",
    "split = 'train'\n",
    "split_ = split_map[verify_str_arg(split.lower(), \"   \", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "# print(\"using data split:\",split_)\n",
    "splits = _load_csv(\"list_eval_partition.txt\")\n",
    "# print(splits.data.shape)\n",
    "identity = _load_csv(\"identity_CelebA.txt\")\n",
    "# bbox = _load_csv(\"list_bbox_celeba.txt\", header=1)\n",
    "# landmarks_align = _load_csv(\"list_landmarks_align_celeba.txt\", header=1)\n",
    "attr = _load_csv(\"list_attr_celeba.txt\", header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask1 = slice(None) if split_ is None else (splits.data == split_).squeeze() # mask for train valid and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "identity = identity.data[:]\n",
    "# bbox = bbox.data[:]\n",
    "# andmarks_align = landmarks_align.data[:]\n",
    "attr_names = attr.header\n",
    "attr = attr.data[:]\n",
    "attr = torch.div(attr + 1, 2, rounding_mode=\"floor\") # map from {-1, 1} to {0, 1}\n",
    "\n",
    "classes = np.array([8, 31])\n",
    "attr = attr.cpu().detach().numpy()\n",
    "attr = attr[:, classes]\n",
    "num_attrs = int(len(classes))\n",
    "C = np.array([2 ** x for x in range(num_attrs)]).reshape(num_attrs,1)\n",
    "print(C)\n",
    "class_list = np.dot(attr, C)\n",
    "# print(\"class_list\", class_list.shape)\n",
    "targets_ = np.squeeze(class_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing class information\n",
      "['Black_Hair' 'Smiling']\n",
      "selected label:[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "maxnumber of imgs per class:100000\n",
      "##################################################\n",
      "statistic information for the whole celebA dataset\n",
      "class 0: number [79716] before masking\n",
      "class 1: number [25214] before masking\n",
      "class 2: number [74411] before masking\n",
      "class 3: number [23258] before masking\n",
      "class 4: number [0] before masking\n",
      "class 5: number [0] before masking\n",
      "class 6: number [0] before masking\n",
      "class 7: number [0] before masking\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"showing class information\")\n",
    "attr_names = np.array(attr_names)[classes]\n",
    "print(attr_names)\n",
    "selected_labels = [0,1,2,3,4,5,6,7]\n",
    "num_imgs_per_class = 100000\n",
    "selected_pos = np.array([])\n",
    "mask2 = np.zeros(splits.data.shape[0],dtype=bool) # mask of label classes\n",
    "print(f'selected label:{selected_labels}')\n",
    "print(f'maxnumber of imgs per class:{num_imgs_per_class}')\n",
    "\n",
    "print(\"##################################################\")\n",
    "print(\"statistic information for the whole celebA dataset\")\n",
    "for i in selected_labels:\n",
    "    temp = class_list == i\n",
    "    print(f\"class {i}: number {sum(temp)} before masking\")\n",
    "    pos_temp,_ = np.where(class_list == i)\n",
    "    pos_temp = np.array(pos_temp)\n",
    "    np.random.shuffle(pos_temp)\n",
    "    selected_pos = np.concatenate((selected_pos, pos_temp[:num_imgs_per_class]))\n",
    "print(\"##################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_subset_mask(remove_label, splits, attr, split_name):\n",
    "    split_map = {\n",
    "    \"train\": 0,\n",
    "    \"valid\": 1,\n",
    "    \"test\": 2,\n",
    "    \"all\": None,\n",
    "    }\n",
    "    split_name = split_name\n",
    "    split_ = split_map[verify_str_arg(split_name.lower(), \"   \", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "    mask1 = slice(None) if split_ is None else (splits.data == split_).squeeze() # mask for train valid and test data\n",
    "    mask1 = mask1.cpu().detach().numpy()\n",
    "\n",
    "    attr_names = attr.header\n",
    "    attr_ = attr.data[:]\n",
    "    attr_ = torch.div(attr_ + 1, 2, rounding_mode=\"floor\") # map from {-1, 1} to {0, 1}\n",
    "    attr_ = attr_.cpu().detach().numpy()\n",
    "    print(\"attr_\", attr_.shape)\n",
    "\n",
    "    classes = np.array([19, 31, 34])\n",
    "    attr_ = attr_[:, classes]\n",
    "    num_attrs = int(len(classes))\n",
    "    print(\"attr_\", attr_.shape)\n",
    "    C = np.array([2 ** x for x in range(num_attrs)]).reshape(num_attrs, 1)\n",
    "    print(\"C\", C.shape)\n",
    "    class_list = np.matmul(attr_, C)\n",
    "    print(\"Class_list\", class_list.shape)\n",
    "    \n",
    "    selected_labels = [0,1,2,3,4,5,6,7]\n",
    "    selected_labels.remove(remove_label)\n",
    "    num_imgs_per_class = 1000000000\n",
    "    # selected_pos = np.array([])\n",
    "    mask2 = np.zeros(splits.data.shape[0],dtype=bool) # mask of label classes\n",
    "    print(\"mask2\", mask2.shape)\n",
    "    print(f'selected label:{selected_labels}', mask2.shape)\n",
    "    print(f'maxnumber of imgs per class:{num_imgs_per_class}')\n",
    "\n",
    "    print(\"statistic information for the whole celebA dataset\")\n",
    "    for i in selected_labels[:1]:\n",
    "        indexor = class_list == i\n",
    "        indexor = np.array(indexor, dtype=bool)\n",
    "        print(f\"class {i}: number {sum(indexor)} \")\n",
    "        mask2 = np.logical_or(mask2, indexor)\n",
    "        # pos_temp,_ = np.where(class_list == i)\n",
    "        # pos_temp = np.array(pos_temp)\n",
    "        # np.random.shuffle(pos_temp)\n",
    "        # selected_pos = np.concatenate((selected_pos, pos_temp[:]))\n",
    "    # selected_pos = np.array(selected_pos,dtype=int)\n",
    "    # mask2[selected_pos] = True\n",
    "    # mask2 = torch.from_numpy(mask2)\n",
    "\n",
    "    mask = np.logical_and(mask1, mask2)\n",
    "\n",
    "    used_attr_names = np.array(attr_names)[classes]\n",
    "    print(\"statistic information for the CUNSTOM dataset\")\n",
    "    print(\"showing class information\")\n",
    "    print(used_attr_names)\n",
    "\n",
    "    print(class_list.shape, mask.shape)\n",
    "    class_list = np.array(class_list, dtype=int)[mask]\n",
    "    for i in range(2**(len(classes))):\n",
    "        temp = class_list == i\n",
    "        print(f\"class {i}: number {sum(temp)}\")\n",
    "        \n",
    "    mask_path = f'mask_npy/celeba_{classes[0]}_{classes[1]}_{classes[2]}_no{remove_label}_{split_name}.npy'\n",
    "    np.save(mask_path, mask)\n",
    "    print(f'mask saving to {mask_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_ (202599, 40)\n",
      "attr_ (202599, 3)\n",
      "C (3, 1)\n",
      "Class_list (202599, 1)\n",
      "selected label:[0, 1, 2, 3, 4, 5, 6] (202599,)\n",
      "maxnumber of imgs per class:1000000000\n",
      "statistic information for the whole celebA dataset\n",
      "class 0: number [81666] \n"
     ]
    }
   ],
   "source": [
    "splits = _load_csv(\"list_eval_partition.txt\")\n",
    "attr = _load_csv(\"list_attr_celeba.txt\", header=1)\n",
    "find_subset_mask(7, splits, attr, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected label:[0, 1, 2, 3, 4, 5, 6]\n",
      "maxnumber of imgs per class:1000000000\n",
      "##################################################\n",
      "statistic information for the whole celebA dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m7\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m split_name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 5\u001b[0m         find_subset_mask(i, splits, attr, split_name)\n",
      "Cell \u001b[0;32mIn[28], line 37\u001b[0m, in \u001b[0;36mfind_subset_mask\u001b[0;34m(remove_label, splits, attr, split_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m     indexor \u001b[39m=\u001b[39m class_list \u001b[39m==\u001b[39m i\n\u001b[1;32m     36\u001b[0m     \u001b[39m# print(f\"class {i}: number {sum(temp)} before masking\")\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     mask2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlogical_and(mask2, indexor)\n\u001b[1;32m     38\u001b[0m     \u001b[39m# pos_temp,_ = np.where(class_list == i)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[39m# pos_temp = np.array(pos_temp)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39m# np.random.shuffle(pos_temp)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39m# selected_pos = np.concatenate((selected_pos, pos_temp[:]))\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m##################################################\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = _load_csv(\"list_eval_partition.txt\")\n",
    "attr = _load_csv(\"list_attr_celeba.txt\", header=1)\n",
    "for i in [7]:\n",
    "    for split_name in ['train','valid','test']:\n",
    "        find_subset_mask(i, splits, attr, split_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from img_utils.image_transform import NumpyResize, pil_loader\n",
    "\n",
    "def select_subset_images(mask_cls, inputPath, outputPath, maxNumber):\n",
    "    splits = _load_csv(\"list_eval_partition.txt\")\n",
    "    mask_cls = np.load(mask_cls)\n",
    "    mask_cls = torch.Tensor(mask_cls)\n",
    "    mask_cls_ = torch.squeeze(torch.nonzero(mask_cls))\n",
    "    print(mask_cls_.shape)\n",
    "    imgList = [splits.index[i] for i in torch.squeeze(torch.nonzero(mask_cls))]\n",
    "    numImgs = len(imgList)\n",
    "    print('Number of Images:', numImgs)\n",
    "\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.mkdir(outputPath)\n",
    "\n",
    "    for index, item in enumerate(imgList[:maxNumber]):\n",
    "        in_path = os.path.join(inputPath, item)\n",
    "        img = np.array(pil_loader(in_path))\n",
    "        out_path = os.path.join(outputPath, item)\n",
    "        imageio.imwrite(out_path, img)\n",
    "    print(\"Finished saving subdataset to\", outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144122])\n",
      "Number of Images: 144122\n",
      "Finished saving subdataset to data/celeba_19_31_34_no7_train\n"
     ]
    }
   ],
   "source": [
    "mask = \"mask_npy/celeba_19_31_34_no7_full_train.npy\"\n",
    "input = \"data/celebA/celeba/img_align_celeba/\"\n",
    "ouput = \"data/celeba_19_31_34_no7_train\"\n",
    "select_subset_images(mask, input, ouput, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_cls_dataset(class_list, attr_names, split, inputPath, outputPath):\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.mkdir(outputPath)\n",
    "    if not os.path.isdir(os.path.join(outputPath,split)):\n",
    "        os.mkdir(os.path.join(outputPath,split))\n",
    "    split_map = {\n",
    "    \"train\": 0,\n",
    "    \"valid\": 1,\n",
    "    \"test\": 2,\n",
    "    \"all\": None,\n",
    "    }\n",
    "    split = split\n",
    "    split_ = split_map[verify_str_arg(split.lower(), \" \", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "    splits = _load_csv(\"list_eval_partition.txt\")\n",
    "\n",
    "    mask1 = slice(None) if split_ is None else (splits.data == split_).squeeze() # mask for train valid and test data\n",
    "    \n",
    "    selected_labels = [0,1,2,3,4,5,6,7]\n",
    "    num_imgs_per_class = 10000\n",
    "    selected_pos = np.array([])\n",
    "    # mask2 = np.zeros(splits.data.shape[0],dtype=bool) # mask of label classes\n",
    "    print(f'selected label:{selected_labels}')\n",
    "    print(f'maxnumber of imgs per class:{num_imgs_per_class}')\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    print(\"statistic information for the whole celebA dataset\")\n",
    "    for i in selected_labels:\n",
    "        temp = class_list == i\n",
    "        temp = torch.from_numpy(np.squeeze(temp))\n",
    "        # print(temp.shape)\n",
    "        # print(mask1.shape)\n",
    "        print(f\"class {i}: number {sum(temp)} before masking\")\n",
    "        mask = mask1*temp\n",
    "        print(mask.shape)\n",
    "        ouputPathTemp= os.path.join(outputPath, split, str(i))\n",
    "        print(outputPath)\n",
    "        select_subset(mask ,inputPath, ouputPathTemp, num_imgs_per_class)\n",
    "    print(\"##################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputPath = \"data/celebA/celeba/img_align_celeba\"\n",
    "outputPath = 'celebA_attrs1_cls'\n",
    "create_cls_dataset(class_list, attr_names, 'train', inputPath, outputPath)\n",
    "create_cls_dataset(class_list, attr_names, 'valid', inputPath, outputPath)\n",
    "create_cls_dataset(class_list, attr_names, 'test', inputPath, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "0: ['Black_Hair' 'Eyeglasses' 'Male'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ff365ceae61721b1c9fb61a0660a1cb6c117b14f6f5e60673ad44067b8057dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
